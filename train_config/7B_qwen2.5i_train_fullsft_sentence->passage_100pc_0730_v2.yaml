# ### goal
# # Train sentence Qwen2.5 7B Instruct on 2 H800 80GB
# # 同样的设置，增加了batch size
# # V2 修改cutoff length

# ### model
# model_name_or_path: saves/Qwen2.5-7B-Instruct-Braille/7B_qwen2.5i_train_fullsft_sentence_100pc_0730_v1/checkpoint-10000
# trust_remote_code: true

# ### method
# stage: sft
# do_train: true
# finetuning_type: full
# # pure_bf16: true
# "bf16": true
# # choices: [ds_z0_config.json, ds_z2_config.json, ds_z3_config.json]
# deepspeed: train_config/deepspeed/ds_z3_config.json  
# # enable_liger_kernel: true
# # use_unsloth_gc: true


# ### dataset
# dataset: passage_100pc_train_0727_v2
# template: qwen # sharegpt
# cutoff_len: 2048
# # max_samples: 500
# overwrite_cache: true
# preprocessing_num_workers: 4

# ### output
# output_dir: saves/Qwen2.5-7B-Instruct-Braille/7B_sentence->passage_100pc_qwen2.5i_train_fullsft_0730_v2/
# logging_steps: 10
# save_steps: 500
# plot_loss: true
# overwrite_output_dir: true

# ### train
# per_device_train_batch_size: 4
# gradient_accumulation_steps: 1
# learning_rate: 4.0e-5
# num_train_epochs: 1.0
# lr_scheduler_type: cosine
# warmup_ratio: 0.05
# # bf16: true
# ddp_timeout: 180000000
# train_on_prompt: false
# report_to: swanlab  # choices: [none, wandb, tensorboard, swanlab, mlflow]
# flash_attn: auto
# disable_shuffling: true

# ### eval
# eval_dataset: passage_100pc_val_0727_v2
# per_device_eval_batch_size: 4
# eval_strategy: steps
# eval_steps: 500
# # predict_with_generate: true
# do_eval: true
# # do_predict: true


########
# Test 1 Passage_100pc_v2
### model
model_name_or_path: saves/Qwen2.5-7B-Instruct-Braille/7B_sentence->passage_100pc_qwen2.5i_train_fullsft_0730_v2/checkpoint-3397
trust_remote_code: true

### method
stage: sft
do_predict: true
finetuning_type: full

### dataset
eval_dataset: passage_100pc_test_0727_v2
template: qwen
cutoff_len: 2048
preprocessing_num_workers: 32
dataloader_num_workers: 16

### output
output_dir: saves/Qwen2.5-7B-Instruct-Braille/7B_sentence->passage_100pc_qwen2.5i_train_fullsft_0730_v2/test_100pc_v2
overwrite_output_dir: true
report_to: none  # choices: [none, wandb, tensorboard, swanlab, mlflow]

### evaluation
per_device_eval_batch_size: 20
predict_with_generate: true
ddp_timeout: 180000000